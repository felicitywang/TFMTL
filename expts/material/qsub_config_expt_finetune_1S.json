{
    // meta-config
    // Modify these!!!
    // Change these paths to yours
    "bashrc_path": "/home/fwang/.bashrc",
    "cpu_venv": "source /home/fwang/cpu/bin/activate",
    "gpu_venv": "source /home/fwang/gpu/bin/activate",
    "code_path": "/export/a08/fwang/tfmtl/expts/scripts/discriminative_driver.py",
    "email": "fwang40@jhu.edu",
    "username": "fwang",
    "cpu_or_gpu": "cpu",
    // main expts folder
    "root_dir": "/export/a08/fwang/tfmtl/expts/material",
    // "root_dir": ".",
    // When in debug mode, write shell scripts but do to qsub
    // You can also run shell scripts manually
    "debug": false,
    // mode for driver script: train/test/predict/finetune
    // Modify these!!!
    "mode": "finetune",
    // comment if classification(default)
    // "task": "regression",
    "architecture":
    "dan_meanmax_relu_0.1_nopretrain",
    // "dan_meanmax_relu_0.1_glove_only_nofinetune",
    // input key: default tokens
    // which domains to use
    "domains": [
        "GOV",
        "BUS",
        "LAW",
        "MIL",
        "REL"
    ],
    // experiment name
    "expt_setup_name": "",
    /****************for finetune mode only*****************/
    // INIT(PRE-TRAIN) dataset name
    // "init_dataset_suffix": "_train_syn_p1000r1000_valid_gold_one",
    "init_dataset_suffix": [
        //
        "_gold_only"
        // "_syn_p1000r1000"
        // "_train_syn_p1000r1000_valid_gold_oracle",
        // "_syn_p1000r1000_syn_p1000r1000_para",
        // "_train_syn_p1000r1000_syn_p1000r1000_para_valid_gold_oracle"
    ],
    "init_dataset_name": "<domains><init_dataset_suffix>",
    // TODO combine turk finetune data
    // FINE-TUNE dataset name
    "finetune_dataset_suffix": [
        //
        "_turk_90_50",
        "_turk_80_50",
        "_turk_70_50",
        "_turk_60_50",
        "_turk_50_50"
    ],
    "finetune_dataset_name": "<domains>_init<init_dataset_suffix>_finetune<finetune_dataset_suffix>",
    // where to load the INIT model
    "checkpoint_dir_init": "<root_dir>/data/results/<expt_setup_name>/<init_name>/ckpt",
    /****************for finetune mode only*****************/
    // which args to use
    "args_paths":
    //
    "min_1_max_-1_vocab_-1_doc_-1_tok_lower",
    // "min_1_max_-1_vocab_-1_doc_-1_tok_lower_glove.6B.300d_only",
    // No need to modify
    // CLSP Grid related
    // for gpu: total_slots = gpu quota (=5)
    //          slots_per_job = 1
    // for cpu: total_slots = cpu quota (=100)
    //          slots_per_job = # cpu cores to use
    // whether to use cpu or gpu
    "gpu_total_slots": 5,
    "gpu_slots_per_job": 2,
    "cpu_total_slots": 100,
    "cpu_slots_per_job": 2,
    // mem_ram in GB
    "mem_ram": 3,
    "num_intra_threads": 1,
    "num_inter_threads": 1,
    // Hyper-parameters / default relative paths
    // datasets
    "datasets": "<domains>",
    // dataset_name
    "dataset_name": "<domains><dataset_suffixes>",
    // dataset paths: where the data.json.gz is stored
    "dataset_paths": "<root_dir>/data/tf/single/<dataset_name>/<args_paths>",
    // topics paths
    "topics_paths": "<root_dir>/data/json/<dataset_name>",
    // where to store results
    "results_dir": "<root_dir>/data/results/<expt_setup_name>/<name>",
    // where to store models(checkpoints)
    "checkpoint_dir": "<root_dir>/data/results/<expt_setup_name>/<name>/ckpt",
    // for finetune mode only
    // where to store summaries(for tensorboard), comment if not storing summaries
    // "summaries_dir": "<root_dir>/data/results/<expt_setup_name>/<name>/summ",
    // where to store logs
    "log_file": "<root_dir>/data/results/<expt_setup_name>/<name>/<mode>.log",
    // configuration of encoders.json, will be read to generate encoders.json for each dataset
    "encoder_config_file": "<root_dir>/data/results/<expt_setup_name>/<name>/encoders.json",
    // what architecture in encoders.json to use
    // default to false in stl mode
    "embedders_tied": false,
    "extractors_tied": false,
    // Optional to modify
    "num_train_epochs": 50,
    // no early stopping when 1.0
    "early_stopping_acc_threshold": 1.0,
    // only needed when there's early stopping
    // "patience": 3,
    // default to 1 in STL mode
    "alphas": "1",
    // default to 2 for MATERIAL
    "class_sizes": "2",
    "model": "mult",
    "shared_mlp_layers": 0,
    "shared_hidden_dims": 0,
    // how many MLP layers and how dimensions of each
    "private_mlp_layers": 1,
    "private_hidden_dims": 128,
    "input_keep_prob": 1.0,
    "output_keep_prob": 1.0,
    "l2_weight": 0.0,
    "optimizer": "rmsprop",
    "lr0": 0.0001,
    // classification
    "metrics": "Acc Precision_Macro Recall_Macro F1_Macro",
    "tuning_metric": "Acc",
    // regression
    // "metrics": "Acc MSE",
    // "tuning_metric": "MSE",
    // "reporting_metric": "Acc MSE",
    "seed": [
        42
    ]
}